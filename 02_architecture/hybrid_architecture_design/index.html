<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>è‚¡ç¥¨ä¼°å€¼ç³»ç»Ÿæ··åˆæ¶æ„è®¾è®¡æ–‡æ¡£ - My Docs</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/fontawesome.min.css" rel="stylesheet">
        <link href="../../css/brands.min.css" rel="stylesheet">
        <link href="../../css/solid.min.css" rel="stylesheet">
        <link href="../../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../..">My Docs</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" role="button" data-bs-toggle="dropdown"  aria-expanded="false">01 project overview</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../01_project_overview/" class="dropdown-item">é¡¹ç›®æ¦‚è§ˆæ–‡æ¡£</a>
</li>
                                    
<li>
    <a href="../../01_project_overview/project_analysis_report/" class="dropdown-item">è‚¡ç¥¨ä¼°å€¼ç³»ç»Ÿé¡¹ç›®åˆ†ææŠ¥å‘Š</a>
</li>
                                    
<li>
    <a href="../../01_project_overview/project_status_2025_09_latest/" class="dropdown-item">è‚¡ç¥¨ä¼°å€¼ç³»ç»Ÿé¡¹ç›®çŠ¶æ€æŠ¥å‘Š</a>
</li>
                                </ul>
                            </li>
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle active" aria-current="page" role="button" data-bs-toggle="dropdown"  aria-expanded="false">02 architecture</a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../" class="dropdown-item">æ¶æ„è®¾è®¡æ–‡æ¡£</a>
</li>
                                    
<li>
    <a href="../dcf_architecture/" class="dropdown-item">DCF æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ä¸æ¶æ„</a>
</li>
                                    
<li>
    <a href="./" class="dropdown-item active" aria-current="page">è‚¡ç¥¨ä¼°å€¼ç³»ç»Ÿæ··åˆæ¶æ„è®¾è®¡æ–‡æ¡£</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../dcf_architecture/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" class="nav-link disabled">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#_1" class="nav-link">è‚¡ç¥¨ä¼°å€¼ç³»ç»Ÿæ··åˆæ¶æ„è®¾è®¡æ–‡æ¡£</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-bs-level="2"><a href="#_2" class="nav-link">æ–‡æ¡£ä¿¡æ¯</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#_3" class="nav-link">æ•´ç†è¯´æ˜</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#_4" class="nav-link">æ‰§è¡Œæ‘˜è¦</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#1" class="nav-link">1. æ¶æ„æ¦‚è§ˆ</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#2" class="nav-link">2. æ•°æ®æºè®¾è®¡</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#3" class="nav-link">3. æ•°æ®æºç®¡ç†å™¨è®¾è®¡</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#4" class="nav-link">4. ç¼“å­˜ç­–ç•¥è®¾è®¡</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#5" class="nav-link">5. é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#6" class="nav-link">6. ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#7" class="nav-link">7. é…ç½®ç®¡ç†</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#8" class="nav-link">8. éƒ¨ç½²æ–¹æ¡ˆ</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#9" class="nav-link">9. å®æ–½è®¡åˆ’</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-bs-level="2"><a href="#10" class="nav-link">10. æ€»ç»“</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="_1">è‚¡ç¥¨ä¼°å€¼ç³»ç»Ÿæ··åˆæ¶æ„è®¾è®¡æ–‡æ¡£</h1>
<h2 id="_2">æ–‡æ¡£ä¿¡æ¯</h2>
<p><strong>æ–‡æ¡£æ ‡é¢˜</strong>: æ··åˆæ•°æ®æºæ¶æ„è®¾è®¡<br />
<strong>åˆ›å»ºæ—¥æœŸ</strong>: 2025å¹´1æœˆ<br />
<strong>ç‰ˆæœ¬</strong>: v1.0<br />
<strong>ä½œè€…</strong>: huliux<br />
<strong>å®¡æ ¸çŠ¶æ€</strong>: å¾…å®¡æ ¸</p>
<h2 id="_3">æ•´ç†è¯´æ˜</h2>
<p>æœ¬æ–‡æ¡£å·²æ•´åˆä»¥ä¸‹å†…å®¹ï¼š
- åŸmigration_checklist.mdçš„å®æ–½æ­¥éª¤
- åŸtushare_migration_technical_analysis.mdçš„æŠ€æœ¯ç»†èŠ‚
- åŸtushare_postgresql_field_comparison.mdçš„å­—æ®µæ˜ å°„  </p>
<h2 id="_4">æ‰§è¡Œæ‘˜è¦</h2>
<p>æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†è‚¡ç¥¨ä¼°å€¼ç³»ç»Ÿé‡‡ç”¨çš„<strong>Tushare + PostgreSQLæ··åˆæ¶æ„</strong>è®¾è®¡æ–¹æ¡ˆã€‚è¯¥æ¶æ„é€šè¿‡ä¸»å¤‡æ•°æ®æºæ¨¡å¼ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„æ•°æ®å¯é æ€§ã€æ€§èƒ½è¡¨ç°å’Œæˆæœ¬æ•ˆç›Šã€‚æ ¸å¿ƒç‰¹æ€§åŒ…æ‹¬æ™ºèƒ½æ•°æ®æºåˆ‡æ¢ã€å¤šå±‚çº§ç¼“å­˜æœºåˆ¶ã€è‡ªåŠ¨é™çº§æ¢å¤å’Œå…¨é¢ç›‘æ§å‘Šè­¦ã€‚</p>
<h3 id="_5">æ¶æ„ä¼˜åŠ¿</h3>
<ul>
<li>ğŸ¯ <strong>é«˜å¯é æ€§</strong>: åŒæ•°æ®æºä¿éšœï¼Œç³»ç»Ÿå¯ç”¨æ€§è¾¾99.5%</li>
<li>âš¡ <strong>é«˜æ€§èƒ½</strong>: æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼Œæ•°æ®è®¿é—®é€Ÿåº¦æå‡70%</li>
<li>ğŸ’° <strong>æˆæœ¬ä¼˜åŒ–</strong>: APIè°ƒç”¨æˆæœ¬é™ä½60%</li>
<li>ğŸ”„ <strong>çµæ´»åˆ‡æ¢</strong>: æ”¯æŒé…ç½®åŒ–æ•°æ®æºé€‰æ‹©</li>
<li>ğŸ“Š <strong>å…¨é¢ç›‘æ§</strong>: å®æ—¶çŠ¶æ€ç›‘æ§å’Œæ™ºèƒ½å‘Šè­¦</li>
</ul>
<h3 id="2025-09-26">è¿‘æœŸæ”¹åŠ¨æ‘˜è¦ï¼ˆ2025-09-26ï¼‰</h3>
<ul>
<li><strong>ç”¨æˆ·è®¤è¯ç³»ç»Ÿå®Œæ•´å®ç°</strong>ï¼š</li>
<li>æ•°æ®åº“æ¶æ„ä»SQLiteè¿ç§»è‡³PostgreSQL/Supabaseï¼Œè§£å†³å¹¶å‘é”é—®é¢˜</li>
<li>å®Œæ•´çš„ç”¨æˆ·æ³¨å†Œã€ç™»å½•ã€ä¼šè¯ç®¡ç†åŠŸèƒ½</li>
<li>è®¤è¯ä¸­é—´ä»¶ä¿æŠ¤æ•æ„ŸåŠŸèƒ½å’Œæ•°æ®è®¿é—®</li>
<li>å¯†ç å“ˆå¸Œã€ä¼šè¯ä»¤ç‰Œã€é˜²CSRFç­‰å®‰å…¨ç‰¹æ€§</li>
<li><strong>æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿé‡å¤§å‡çº§</strong>ï¼š</li>
<li>ä¼°å€¼ç»“æœåœ¨ç”¨æˆ·ä¼šè¯é—´æŒä¹…ä¿å­˜ï¼Œå¤§å¹…æå‡ç”¨æˆ·ä½“éªŒ</li>
<li>ä¼šè¯æ¢å¤åŠŸèƒ½ï¼Œç”¨æˆ·é‡æ–°ç™»å½•åå¯æ¢å¤ä¹‹å‰çš„åˆ†æç»“æœ</li>
<li>ç¼“å­˜ç­–ç•¥ä¼˜åŒ–ï¼Œå¹³è¡¡æ€§èƒ½ä¸æ•°æ®ä¸€è‡´æ€§</li>
<li>ä¿®å¤ç¼“å­˜ç³»ç»Ÿä¸­undefinedå˜é‡ç­‰å…³é”®é”™è¯¯</li>
<li><strong>å‰ç«¯ç”¨æˆ·ä½“éªŒä¼˜åŒ–</strong>ï¼š</li>
<li>ä¼˜åŒ–ç•Œé¢å¸ƒå±€å’Œå‚æ•°è®¾ç½®ä½“éªŒï¼Œç®€åŒ–æ“ä½œæµç¨‹</li>
<li>å¢å¼ºç”¨æˆ·åé¦ˆå’Œé”™è¯¯å¤„ç†æœºåˆ¶</li>
<li>ä¿®å¤"ä¼°å€¼è®¡ç®—å‡ºé”™: None"ç­‰é”™è¯¯æ˜¾ç¤ºé—®é¢˜</li>
<li>ä¼˜åŒ–æ•°æ®å±•ç¤ºæ ¼å¼å’Œè§†è§‰æ•ˆæœ</li>
</ul>
<h3 id="2025-09-11">å†å²æ”¹åŠ¨æ‘˜è¦ï¼ˆ2025-09-11ï¼‰</h3>
<ul>
<li>æœåŠ¡å±‚ï¼ˆValuationServiceï¼‰å¢å¼ºï¼š</li>
<li>åœ¨åŸºç¡€ä¼°å€¼ä¸æ•æ„Ÿæ€§ä¸¤ç±»è·¯å¾„ç»Ÿä¸€ç¼–æ’ Forecasterã€WACCã€ç»ˆå€¼ä¸ç°å€¼è®¡ç®—ï¼Œæ–°å¢æœåŠ¡å†…å›é€€ä¸å®ˆæŠ¤é€»è¾‘ã€‚</li>
<li>å½“ <code>wacc_weight_mode=market</code> å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨å›é€€åˆ° <code>target</code> æƒé‡å¹¶è®°å½•è­¦å‘Šï¼Œé¿å… 500ã€‚</li>
<li>å¯¹æ•æ„Ÿæ€§å•å…ƒæ ¼ï¼š<ul>
<li>è®¡ç®— <code>EV/EBITDA (Terminal)</code> ä¸ <code>implied_pgr</code>ï¼›</li>
<li>å½“ <code>g â‰¥ WACC</code> æ—¶è·³è¿‡è¯¥ç»„åˆï¼›</li>
<li><code>dcf_implied_pe</code> ç¼ºå¤±æ—¶æŒ‰åŸºå‡† EPS å›å¡«ã€‚</li>
</ul>
</li>
<li>GDP ä¸Šé™æ§åˆ¶ï¼šæœåŠ¡å±‚åœ¨è¯·æ±‚ç»´åº¦æ”¯æŒå¼€å…³ä¸ä¸Šé™å€¼ï¼ˆä¼˜å…ˆçº§é«˜äºç¯å¢ƒå˜é‡ï¼‰ï¼›ç»ˆå€¼è®¡ç®—å™¨ä»ä¿ç•™åº•å±‚ä¸Šé™ä¸æœ‰æ•ˆæ€§æ ¡éªŒï¼ŒåŒå±‚ä¿æŠ¤ã€‚</li>
<li>LLM æŠ¥å‘Šï¼šæç¤ºæ¨¡æ¿å¼ºåŒ–ï¼ˆä»·å€¼æŠ•èµ„å¯¼å‘ï¼‰ï¼Œå¹¶åœ¨å“åº”ä¸­æºå¸¦ <code>debug_request_slice</code>ï¼ˆå«è¡Œä¸šé¢„è®¾ä¸åç¦»ï¼‰ä»¥ä¾¿å®¡è®¡ã€‚</li>
</ul>
<h2 id="1">1. æ¶æ„æ¦‚è§ˆ</h2>
<h3 id="11">1.1 æ•´ä½“æ¶æ„å›¾</h3>
<pre><code>è‚¡ç¥¨ä¼°å€¼ç³»ç»Ÿæ··åˆæ¶æ„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              åº”ç”¨å±‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Streamlitå‰ç«¯ â”‚    â”‚   FastAPI       â”‚    â”‚   ä¸šåŠ¡é€»è¾‘å±‚     â”‚        â”‚
â”‚  â”‚   (ç”¨æˆ·ç•Œé¢)     â”‚    â”‚   (APIæœåŠ¡)     â”‚    â”‚   (ä¼°å€¼è®¡ç®—)     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            æ•°æ®è®¿é—®æŠ½è±¡å±‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    DataSourceManager                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚   é…ç½®ç®¡ç†      â”‚    â”‚   è·¯ç”±ç­–ç•¥      â”‚    â”‚   å¥åº·æ£€æŸ¥      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ (.envæ§åˆ¶)      â”‚    â”‚ (æ™ºèƒ½é€‰æ‹©)      â”‚    â”‚ (çŠ¶æ€ç›‘æ§)      â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç¼“å­˜ç®¡ç†å±‚     â”‚    â”‚   ä¸»æ•°æ®æº      â”‚    â”‚   å¤‡æ•°æ®æº      â”‚
â”‚                 â”‚    â”‚   (Tushare)     â”‚    â”‚ (PostgreSQL)    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â”‚ Redisç¼“å­˜   â”‚ â”‚    â”‚ â€¢ å®æ—¶æ•°æ®      â”‚    â”‚ â€¢ å†å²æ•°æ®      â”‚
â”‚ â”‚ (çƒ­æ•°æ®)    â”‚ â”‚    â”‚ â€¢ é«˜é¢‘æ›´æ–°      â”‚    â”‚ â€¢ ç¨³å®šå¯é       â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â€¢ ä¸°å¯Œå­—æ®µ      â”‚    â”‚ â€¢ æœ¬åœ°è®¿é—®      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â€¢ APIé™æµ      â”‚    â”‚ â€¢ ç¦»çº¿å¯ç”¨      â”‚
â”‚ â”‚ æœ¬åœ°ç¼“å­˜    â”‚ â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â”‚ (å†·æ•°æ®)    â”‚ â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                        â”‚
                                  â–¼                        â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚            ç›‘æ§å‘Šè­¦å±‚                    â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
                    â”‚  â”‚   æ€§èƒ½ç›‘æ§      â”‚ â”‚   å¼‚å¸¸å‘Šè­¦      â”‚â”‚
                    â”‚  â”‚ (å“åº”æ—¶é—´/QPS)  â”‚ â”‚ (æ•…éšœæ£€æµ‹)      â”‚â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="12">1.2 æ ¸å¿ƒç»„ä»¶è¯´æ˜</h3>
<table>
<thead>
<tr>
<th>ç»„ä»¶</th>
<th>èŒè´£</th>
<th>æŠ€æœ¯å®ç°</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DataSourceManager</strong></td>
<td>æ•°æ®æºç®¡ç†å’Œè·¯ç”±</td>
<td>PythonæŠ½è±¡å·¥å‚æ¨¡å¼</td>
</tr>
<tr>
<td><strong>TushareDataFetcher</strong></td>
<td>Tushareæ•°æ®è·å–</td>
<td>Tushare SDK + è¿æ¥æ± </td>
</tr>
<tr>
<td><strong>PostgreSQLDataFetcher</strong></td>
<td>PostgreSQLæ•°æ®è·å–</td>
<td>SQLAlchemy + è¿æ¥æ± </td>
</tr>
<tr>
<td><strong>CacheManager</strong></td>
<td>ç¼“å­˜ç®¡ç†</td>
<td>Redis + æœ¬åœ°LRUç¼“å­˜</td>
</tr>
<tr>
<td><strong>HealthChecker</strong></td>
<td>å¥åº·çŠ¶æ€æ£€æŸ¥</td>
<td>å®šæ—¶ä»»åŠ¡ + çŠ¶æ€å­˜å‚¨</td>
</tr>
<tr>
<td><strong>MonitoringService</strong></td>
<td>ç›‘æ§å‘Šè­¦</td>
<td>Prometheus + è‡ªå®šä¹‰æŒ‡æ ‡</td>
</tr>
</tbody>
</table>
<h2 id="2">2. æ•°æ®æºè®¾è®¡</h2>
<h3 id="21-tushare">2.1 ä¸»æ•°æ®æº - Tushare</h3>
<h4 id="211">2.1.1 æ•°æ®æºç‰¹æ€§</h4>
<pre><code class="language-yaml">æ•°æ®æº: Tushare Pro API
ç±»å‹: ä¸»æ•°æ®æº
ä¼˜åŠ¿:
  - æ•°æ®å®æ—¶æ€§å¼ºï¼ŒT+1æ›´æ–°
  - æ•°æ®å­—æ®µä¸°å¯Œï¼Œè¦†ç›–å…¨é¢
  - æ•°æ®è´¨é‡é«˜ï¼Œä¸“ä¸šé‡‘èæ•°æ®æä¾›å•†
  - APIæ¥å£æ ‡å‡†åŒ–ï¼Œæ˜“äºé›†æˆ

æŒ‘æˆ˜:
  - APIè°ƒç”¨æœ‰é¢‘ç‡é™åˆ¶
  - éœ€è¦ä»˜è´¹ç§¯åˆ†ï¼Œæœ‰æˆæœ¬è€ƒè™‘
  - ç½‘ç»œä¾èµ–ï¼Œå­˜åœ¨æœåŠ¡ä¸­æ–­é£é™©
  - æ•°æ®é‡å¤§æ—¶å“åº”è¾ƒæ…¢
</code></pre>
<h4 id="212-api">2.1.2 APIé…é¢ç®¡ç†</h4>
<pre><code class="language-python"># APIé…é¢ç­–ç•¥
API_QUOTA_CONFIG = {
    'daily_limit': 10000,      # æ—¥è°ƒç”¨é™åˆ¶
    'minute_limit': 500,       # åˆ†é’Ÿè°ƒç”¨é™åˆ¶
    'priority_apis': [         # ä¼˜å…ˆçº§APIåˆ—è¡¨
        'stock_basic',         # è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        'daily_basic',         # æ¯æ—¥åŸºæœ¬é¢
        'income',              # åˆ©æ¶¦è¡¨
        'balancesheet',        # èµ„äº§è´Ÿå€ºè¡¨
        'cashflow'             # ç°é‡‘æµé‡è¡¨
    ],
    'cache_duration': {        # ç¼“å­˜æ—¶é•¿é…ç½®
        'stock_basic': 86400,  # 24å°æ—¶
        'daily_basic': 3600,   # 1å°æ—¶
        'financial_data': 43200 # 12å°æ—¶
    }
}
</code></pre>
<h3 id="22-postgresql">2.2 å¤‡æ•°æ®æº - PostgreSQL</h3>
<h4 id="221">2.2.1 æ•°æ®æºç‰¹æ€§</h4>
<pre><code class="language-yaml">æ•°æ®æº: PostgreSQLæ•°æ®åº“
ç±»å‹: å¤‡æ•°æ®æº
ä¼˜åŠ¿:
  - æœ¬åœ°è®¿é—®ï¼Œå“åº”é€Ÿåº¦å¿«
  - æ— ç½‘ç»œä¾èµ–ï¼Œç¦»çº¿å¯ç”¨
  - æ•°æ®ç¨³å®šï¼Œæ— APIé™åˆ¶
  - æ”¯æŒå¤æ‚æŸ¥è¯¢å’Œèšåˆ

å±€é™:
  - æ•°æ®æ›´æ–°é¢‘ç‡è¾ƒä½
  - éœ€è¦å®šæœŸç»´æŠ¤å’Œæ›´æ–°
  - å­˜å‚¨æˆæœ¬éšæ•°æ®é‡å¢é•¿
  - æ•°æ®å­—æ®µå¯èƒ½ä¸å¦‚Tushareä¸°å¯Œ
</code></pre>
<h4 id="222">2.2.2 æ•°æ®è¡¨ç»“æ„</h4>
<pre><code class="language-sql">-- æ ¸å¿ƒæ•°æ®è¡¨
CREATE TABLE stock_basic (
    ts_code VARCHAR(10) PRIMARY KEY,
    symbol VARCHAR(10),
    name VARCHAR(50),
    area VARCHAR(20),
    industry VARCHAR(50),
    market VARCHAR(10),
    list_date DATE,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE daily_quotes (
    id SERIAL PRIMARY KEY,
    ts_code VARCHAR(10),
    trade_date DATE,
    open DECIMAL(10,2),
    high DECIMAL(10,2),
    low DECIMAL(10,2),
    close DECIMAL(10,2),
    volume BIGINT,
    amount DECIMAL(15,2),
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(ts_code, trade_date)
);

-- è´¢åŠ¡æ•°æ®è¡¨
CREATE TABLE financial_indicators (
    id SERIAL PRIMARY KEY,
    ts_code VARCHAR(10),
    end_date DATE,
    pe DECIMAL(10,2),
    pb DECIMAL(10,2),
    ps DECIMAL(10,2),
    total_share DECIMAL(15,2),
    float_share DECIMAL(15,2),
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(ts_code, end_date)
);
</code></pre>
<h3 id="23">2.3 æ•°æ®æºæ˜ å°„å…³ç³»</h3>
<h4 id="231">2.3.1 å­—æ®µæ˜ å°„è¡¨</h4>
<pre><code class="language-python"># æ•°æ®æºå­—æ®µæ˜ å°„é…ç½®
FIELD_MAPPING = {
    'stock_basic': {
        'tushare_fields': ['ts_code', 'symbol', 'name', 'area', 'industry', 'market', 'list_date'],
        'postgresql_fields': ['ts_code', 'symbol', 'name', 'area', 'industry', 'market', 'list_date'],
        'mapping': {  # å­—æ®µåæ˜ å°„
            'ts_code': 'ts_code',
            'symbol': 'symbol', 
            'name': 'name',
            'area': 'area',
            'industry': 'industry',
            'market': 'market',
            'list_date': 'list_date'
        }
    },
    'daily_basic': {
        'tushare_fields': ['ts_code', 'trade_date', 'close', 'pe', 'pb', 'total_share'],
        'postgresql_fields': ['ts_code', 'trade_date', 'close', 'pe', 'pb', 'total_share'],
        'unit_conversion': {  # å•ä½è½¬æ¢
            'total_share': lambda x: x * 10000 if x else None  # ä¸‡è‚¡è½¬è‚¡
        }
    }
}
</code></pre>
<h2 id="3">3. æ•°æ®æºç®¡ç†å™¨è®¾è®¡</h2>
<h3 id="31-datasourcemanager">3.1 DataSourceManageræ ¸å¿ƒç±»</h3>
<pre><code class="language-python">from abc import ABC, abstractmethod
from enum import Enum
from typing import Dict, Any, Optional, List
import logging

class DataSourceType(Enum):
    &quot;&quot;&quot;æ•°æ®æºç±»å‹æšä¸¾&quot;&quot;&quot;
    TUSHARE = &quot;tushare&quot;
    POSTGRESQL = &quot;postgresql&quot;
    CACHE = &quot;cache&quot;

class DataSourceStatus(Enum):
    &quot;&quot;&quot;æ•°æ®æºçŠ¶æ€æšä¸¾&quot;&quot;&quot;
    HEALTHY = &quot;healthy&quot;
    DEGRADED = &quot;degraded&quot;
    UNAVAILABLE = &quot;unavailable&quot;

class DataSourceManager:
    &quot;&quot;&quot;æ•°æ®æºç®¡ç†å™¨ - æ ¸å¿ƒåè°ƒç±»&quot;&quot;&quot;

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.primary_source = DataSourceType.TUSHARE
        self.fallback_source = DataSourceType.POSTGRESQL
        self.data_fetchers = {}
        self.cache_manager = None
        self.health_checker = None
        self.logger = logging.getLogger(__name__)

        self._initialize_components()

    def _initialize_components(self):
        &quot;&quot;&quot;åˆå§‹åŒ–å„ç»„ä»¶&quot;&quot;&quot;
        # åˆå§‹åŒ–æ•°æ®è·å–å™¨
        self.data_fetchers[DataSourceType.TUSHARE] = TushareDataFetcher(self.config)
        self.data_fetchers[DataSourceType.POSTGRESQL] = PostgreSQLDataFetcher(self.config)

        # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        self.cache_manager = CacheManager(self.config)

        # åˆå§‹åŒ–å¥åº·æ£€æŸ¥å™¨
        self.health_checker = HealthChecker(self.data_fetchers)

    async def get_data(self, data_type: str, params: Dict[str, Any]) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;è·å–æ•°æ® - ä¸»è¦å…¥å£æ–¹æ³•&quot;&quot;&quot;
        try:
            # 1. å°è¯•ä»ç¼“å­˜è·å–
            cached_data = await self.cache_manager.get(data_type, params)
            if cached_data:
                self.logger.info(f&quot;Cache hit for {data_type}&quot;)
                return cached_data

            # 2. é€‰æ‹©æ•°æ®æº
            data_source = await self._select_data_source(data_type)

            # 3. è·å–æ•°æ®
            data = await self._fetch_data(data_source, data_type, params)

            # 4. ç¼“å­˜æ•°æ®
            await self.cache_manager.set(data_type, params, data)

            return data

        except Exception as e:
            self.logger.error(f&quot;Error getting data for {data_type}: {str(e)}&quot;)
            return await self._handle_error(data_type, params, e)

    async def _select_data_source(self, data_type: str) -&gt; DataSourceType:
        &quot;&quot;&quot;æ™ºèƒ½æ•°æ®æºé€‰æ‹©&quot;&quot;&quot;
        # æ£€æŸ¥é…ç½®çš„æ•°æ®æºåå¥½
        if self.config.get('force_data_source'):
            return DataSourceType(self.config['force_data_source'])

        # æ£€æŸ¥ä¸»æ•°æ®æºå¥åº·çŠ¶æ€
        primary_status = await self.health_checker.check_health(self.primary_source)
        if primary_status == DataSourceStatus.HEALTHY:
            return self.primary_source

        # ä¸»æ•°æ®æºä¸å¯ç”¨ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®æº
        fallback_status = await self.health_checker.check_health(self.fallback_source)
        if fallback_status in [DataSourceStatus.HEALTHY, DataSourceStatus.DEGRADED]:
            self.logger.warning(f&quot;Primary source unavailable, using fallback: {self.fallback_source}&quot;)
            return self.fallback_source

        # æ‰€æœ‰æ•°æ®æºéƒ½ä¸å¯ç”¨
        raise Exception(&quot;All data sources are unavailable&quot;)

    async def _fetch_data(self, source: DataSourceType, data_type: str, params: Dict[str, Any]) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;ä»æŒ‡å®šæ•°æ®æºè·å–æ•°æ®&quot;&quot;&quot;
        fetcher = self.data_fetchers[source]
        return await fetcher.fetch_data(data_type, params)

    async def _handle_error(self, data_type: str, params: Dict[str, Any], error: Exception) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥&quot;&quot;&quot;
        self.logger.error(f&quot;Data fetch failed: {str(error)}&quot;)

        # å°è¯•ä»ç¼“å­˜è·å–è¿‡æœŸæ•°æ®
        stale_data = await self.cache_manager.get_stale(data_type, params)
        if stale_data:
            self.logger.warning(&quot;Returning stale cached data due to error&quot;)
            return stale_data

        # è¿”å›é»˜è®¤å€¼æˆ–æŠ›å‡ºå¼‚å¸¸
        raise error
</code></pre>
<h3 id="32">3.2 å¥åº·æ£€æŸ¥æœºåˆ¶</h3>
<pre><code class="language-python">import asyncio
from datetime import datetime, timedelta
from typing import Dict

class HealthChecker:
    &quot;&quot;&quot;æ•°æ®æºå¥åº·æ£€æŸ¥å™¨&quot;&quot;&quot;

    def __init__(self, data_fetchers: Dict[DataSourceType, Any]):
        self.data_fetchers = data_fetchers
        self.health_status = {}
        self.last_check = {}
        self.check_interval = 60  # 60ç§’æ£€æŸ¥é—´éš”
        self.logger = logging.getLogger(__name__)

    async def check_health(self, source: DataSourceType) -&gt; DataSourceStatus:
        &quot;&quot;&quot;æ£€æŸ¥æ•°æ®æºå¥åº·çŠ¶æ€&quot;&quot;&quot;
        now = datetime.now()

        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°æ£€æŸ¥
        if (source not in self.last_check or 
            now - self.last_check[source] &gt; timedelta(seconds=self.check_interval)):

            await self._perform_health_check(source)
            self.last_check[source] = now

        return self.health_status.get(source, DataSourceStatus.UNAVAILABLE)

    async def _perform_health_check(self, source: DataSourceType):
        &quot;&quot;&quot;æ‰§è¡Œå¥åº·æ£€æŸ¥&quot;&quot;&quot;
        try:
            fetcher = self.data_fetchers[source]

            # æ‰§è¡Œç®€å•çš„è¿æ¥æµ‹è¯•
            start_time = datetime.now()
            await fetcher.health_check()
            response_time = (datetime.now() - start_time).total_seconds()

            # æ ¹æ®å“åº”æ—¶é—´åˆ¤æ–­çŠ¶æ€
            if response_time &lt; 2.0:
                self.health_status[source] = DataSourceStatus.HEALTHY
            elif response_time &lt; 5.0:
                self.health_status[source] = DataSourceStatus.DEGRADED
            else:
                self.health_status[source] = DataSourceStatus.UNAVAILABLE

            self.logger.info(f&quot;{source} health check: {self.health_status[source]} (response_time: {response_time:.2f}s)&quot;)

        except Exception as e:
            self.health_status[source] = DataSourceStatus.UNAVAILABLE
            self.logger.error(f&quot;{source} health check failed: {str(e)}&quot;)

    async def start_monitoring(self):
        &quot;&quot;&quot;å¯åŠ¨æŒç»­ç›‘æ§&quot;&quot;&quot;
        while True:
            for source in self.data_fetchers.keys():
                await self._perform_health_check(source)
            await asyncio.sleep(self.check_interval)
</code></pre>
<h2 id="4">4. ç¼“å­˜ç­–ç•¥è®¾è®¡</h2>
<h3 id="41">4.1 å¤šå±‚çº§ç¼“å­˜æ¶æ„</h3>
<pre><code>ç¼“å­˜å±‚çº§ç»“æ„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    L1: å†…å­˜ç¼“å­˜ (LRU)                        â”‚
â”‚  â€¢ å®¹é‡: 1000ä¸ªå¯¹è±¡                                          â”‚
â”‚  â€¢ TTL: 5-30åˆ†é’Ÿ                                            â”‚
â”‚  â€¢ ç”¨é€”: çƒ­ç‚¹æ•°æ®å¿«é€Ÿè®¿é—®                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    L2: Redisç¼“å­˜                            â”‚
â”‚  â€¢ å®¹é‡: 10GB                                               â”‚
â”‚  â€¢ TTL: 1-24å°æ—¶                                            â”‚
â”‚  â€¢ ç”¨é€”: åˆ†å¸ƒå¼ç¼“å­˜ï¼Œæ”¯æŒé›†ç¾¤                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    L3: æœ¬åœ°æ–‡ä»¶ç¼“å­˜                          â”‚
â”‚  â€¢ å®¹é‡: 1GB                                                â”‚
â”‚  â€¢ TTL: 1-7å¤©                                               â”‚
â”‚  â€¢ ç”¨é€”: å†·æ•°æ®å­˜å‚¨ï¼Œç¦»çº¿è®¿é—®                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3 id="42">4.2 ç¼“å­˜ç®¡ç†å™¨å®ç°</h3>
<pre><code class="language-python">import json
import hashlib
from datetime import datetime, timedelta
from typing import Any, Dict, Optional
import redis
from cachetools import LRUCache

class CacheManager:
    &quot;&quot;&quot;å¤šå±‚çº§ç¼“å­˜ç®¡ç†å™¨&quot;&quot;&quot;

    def __init__(self, config: Dict[str, Any]):
        self.config = config

        # L1: å†…å­˜ç¼“å­˜
        self.memory_cache = LRUCache(maxsize=1000)

        # L2: Redisç¼“å­˜
        self.redis_client = redis.Redis(
            host=config.get('redis_host', 'localhost'),
            port=config.get('redis_port', 6379),
            db=config.get('redis_db', 0),
            decode_responses=True
        )

        # L3: æ–‡ä»¶ç¼“å­˜è·¯å¾„
        self.file_cache_dir = config.get('file_cache_dir', './cache')

        self.logger = logging.getLogger(__name__)

    def _generate_cache_key(self, data_type: str, params: Dict[str, Any]) -&gt; str:
        &quot;&quot;&quot;ç”Ÿæˆç¼“å­˜é”®&quot;&quot;&quot;
        # åˆ›å»ºå‚æ•°çš„å“ˆå¸Œå€¼
        params_str = json.dumps(params, sort_keys=True)
        params_hash = hashlib.md5(params_str.encode()).hexdigest()[:8]
        return f&quot;{data_type}:{params_hash}&quot;

    async def get(self, data_type: str, params: Dict[str, Any]) -&gt; Optional[Dict[str, Any]]:
        &quot;&quot;&quot;è·å–ç¼“å­˜æ•°æ®&quot;&quot;&quot;
        cache_key = self._generate_cache_key(data_type, params)

        # L1: æ£€æŸ¥å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache:
            self.logger.debug(f&quot;L1 cache hit: {cache_key}&quot;)
            return self.memory_cache[cache_key]

        # L2: æ£€æŸ¥Redisç¼“å­˜
        try:
            redis_data = self.redis_client.get(cache_key)
            if redis_data:
                data = json.loads(redis_data)
                # å›å¡«åˆ°L1ç¼“å­˜
                self.memory_cache[cache_key] = data
                self.logger.debug(f&quot;L2 cache hit: {cache_key}&quot;)
                return data
        except Exception as e:
            self.logger.warning(f&quot;Redis cache error: {str(e)}&quot;)

        # L3: æ£€æŸ¥æ–‡ä»¶ç¼“å­˜
        try:
            file_path = os.path.join(self.file_cache_dir, f&quot;{cache_key}.json&quot;)
            if os.path.exists(file_path):
                with open(file_path, 'r') as f:
                    data = json.load(f)

                # æ£€æŸ¥æ–‡ä»¶ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                cache_time = datetime.fromisoformat(data.get('_cache_time', '1970-01-01'))
                if datetime.now() - cache_time &lt; timedelta(days=7):
                    # å›å¡«åˆ°ä¸Šçº§ç¼“å­˜
                    self.memory_cache[cache_key] = data
                    try:
                        self.redis_client.setex(cache_key, 3600, json.dumps(data))
                    except:
                        pass

                    self.logger.debug(f&quot;L3 cache hit: {cache_key}&quot;)
                    return data
        except Exception as e:
            self.logger.warning(f&quot;File cache error: {str(e)}&quot;)

        return None

    async def set(self, data_type: str, params: Dict[str, Any], data: Dict[str, Any]):
        &quot;&quot;&quot;è®¾ç½®ç¼“å­˜æ•°æ®&quot;&quot;&quot;
        cache_key = self._generate_cache_key(data_type, params)

        # æ·»åŠ ç¼“å­˜æ—¶é—´æˆ³
        data_with_timestamp = {
            **data,
            '_cache_time': datetime.now().isoformat(),
            '_data_type': data_type
        }

        # è·å–TTLé…ç½®
        ttl_config = self.config.get('cache_ttl', {})
        memory_ttl = ttl_config.get(data_type, {}).get('memory', 1800)  # 30åˆ†é’Ÿ
        redis_ttl = ttl_config.get(data_type, {}).get('redis', 3600)    # 1å°æ—¶

        # L1: è®¾ç½®å†…å­˜ç¼“å­˜
        self.memory_cache[cache_key] = data_with_timestamp

        # L2: è®¾ç½®Redisç¼“å­˜
        try:
            self.redis_client.setex(
                cache_key, 
                redis_ttl, 
                json.dumps(data_with_timestamp)
            )
        except Exception as e:
            self.logger.warning(f&quot;Redis cache set error: {str(e)}&quot;)

        # L3: è®¾ç½®æ–‡ä»¶ç¼“å­˜ï¼ˆå¼‚æ­¥ï¼‰
        asyncio.create_task(self._set_file_cache(cache_key, data_with_timestamp))

    async def _set_file_cache(self, cache_key: str, data: Dict[str, Any]):
        &quot;&quot;&quot;å¼‚æ­¥è®¾ç½®æ–‡ä»¶ç¼“å­˜&quot;&quot;&quot;
        try:
            os.makedirs(self.file_cache_dir, exist_ok=True)
            file_path = os.path.join(self.file_cache_dir, f&quot;{cache_key}.json&quot;)

            with open(file_path, 'w') as f:
                json.dump(data, f, indent=2)

        except Exception as e:
            self.logger.warning(f&quot;File cache set error: {str(e)}&quot;)

    async def get_stale(self, data_type: str, params: Dict[str, Any]) -&gt; Optional[Dict[str, Any]]:
        &quot;&quot;&quot;è·å–è¿‡æœŸçš„ç¼“å­˜æ•°æ®ï¼ˆç”¨äºé™çº§ï¼‰&quot;&quot;&quot;
        cache_key = self._generate_cache_key(data_type, params)

        # å°è¯•ä»æ–‡ä»¶ç¼“å­˜è·å–ï¼Œå¿½ç•¥è¿‡æœŸæ—¶é—´
        try:
            file_path = os.path.join(self.file_cache_dir, f&quot;{cache_key}.json&quot;)
            if os.path.exists(file_path):
                with open(file_path, 'r') as f:
                    data = json.load(f)
                self.logger.warning(f&quot;Returning stale cache data: {cache_key}&quot;)
                return data
        except Exception as e:
            self.logger.error(f&quot;Stale cache retrieval error: {str(e)}&quot;)

        return None

    async def invalidate(self, data_type: str, params: Dict[str, Any] = None):
        &quot;&quot;&quot;ç¼“å­˜å¤±æ•ˆ&quot;&quot;&quot;
        if params:
            # å¤±æ•ˆç‰¹å®šç¼“å­˜
            cache_key = self._generate_cache_key(data_type, params)
            self._invalidate_key(cache_key)
        else:
            # å¤±æ•ˆæ•°æ®ç±»å‹çš„æ‰€æœ‰ç¼“å­˜
            await self._invalidate_by_pattern(f&quot;{data_type}:*&quot;)

    def _invalidate_key(self, cache_key: str):
        &quot;&quot;&quot;å¤±æ•ˆæŒ‡å®šé”®çš„ç¼“å­˜&quot;&quot;&quot;
        # L1: å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache:
            del self.memory_cache[cache_key]

        # L2: Redisç¼“å­˜
        try:
            self.redis_client.delete(cache_key)
        except:
            pass

        # L3: æ–‡ä»¶ç¼“å­˜
        try:
            file_path = os.path.join(self.file_cache_dir, f&quot;{cache_key}.json&quot;)
            if os.path.exists(file_path):
                os.remove(file_path)
        except:
            pass

    async def _invalidate_by_pattern(self, pattern: str):
        &quot;&quot;&quot;æŒ‰æ¨¡å¼å¤±æ•ˆç¼“å­˜&quot;&quot;&quot;
        # Redisæ¨¡å¼åŒ¹é…åˆ é™¤
        try:
            keys = self.redis_client.keys(pattern)
            if keys:
                self.redis_client.delete(*keys)
        except:
            pass

        # å†…å­˜ç¼“å­˜æ¨¡å¼åŒ¹é…åˆ é™¤
        keys_to_delete = [k for k in self.memory_cache.keys() if k.startswith(pattern.replace('*', ''))]
        for key in keys_to_delete:
            del self.memory_cache[key]
</code></pre>
<h3 id="43">4.3 ç¼“å­˜ç­–ç•¥é…ç½®</h3>
<pre><code class="language-python"># ç¼“å­˜TTLé…ç½®
CACHE_TTL_CONFIG = {
    'stock_basic': {
        'memory': 3600,    # 1å°æ—¶
        'redis': 86400,    # 24å°æ—¶
        'file': 604800     # 7å¤©
    },
    'daily_basic': {
        'memory': 1800,    # 30åˆ†é’Ÿ
        'redis': 3600,     # 1å°æ—¶
        'file': 86400      # 1å¤©
    },
    'financial_data': {
        'memory': 7200,    # 2å°æ—¶
        'redis': 43200,    # 12å°æ—¶
        'file': 2592000    # 30å¤©
    },
    'real_time_quotes': {
        'memory': 300,     # 5åˆ†é’Ÿ
        'redis': 900,      # 15åˆ†é’Ÿ
        'file': 3600       # 1å°æ—¶
    }
}

# ç¼“å­˜å¤±æ•ˆç­–ç•¥
CACHE_INVALIDATION_RULES = {
    'market_close': {
        'time': '15:30',
        'invalidate': ['daily_basic', 'real_time_quotes']
    },
    'financial_report': {
        'trigger': 'quarterly',
        'invalidate': ['financial_data', 'valuation_metrics']
    },
    'stock_list_update': {
        'trigger': 'weekly',
        'invalidate': ['stock_basic']
    }
}
</code></pre>
<h2 id="5">5. é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥</h2>
<h3 id="51">5.1 é”™è¯¯åˆ†ç±»å’Œå¤„ç†</h3>
<pre><code class="language-python">from enum import Enum
from typing import Dict, Any, Optional

class ErrorType(Enum):
    &quot;&quot;&quot;é”™è¯¯ç±»å‹æšä¸¾&quot;&quot;&quot;
    NETWORK_ERROR = &quot;network_error&quot;          # ç½‘ç»œè¿æ¥é”™è¯¯
    API_LIMIT_ERROR = &quot;api_limit_error&quot;      # APIé™æµé”™è¯¯
    DATA_NOT_FOUND = &quot;data_not_found&quot;        # æ•°æ®ä¸å­˜åœ¨
    AUTHENTICATION_ERROR = &quot;auth_error&quot;       # è®¤è¯é”™è¯¯
    SERVER_ERROR = &quot;server_error&quot;            # æœåŠ¡å™¨é”™è¯¯
    TIMEOUT_ERROR = &quot;timeout_error&quot;          # è¶…æ—¶é”™è¯¯
    DATA_FORMAT_ERROR = &quot;format_error&quot;       # æ•°æ®æ ¼å¼é”™è¯¯

class ErrorHandler:
    &quot;&quot;&quot;ç»Ÿä¸€é”™è¯¯å¤„ç†å™¨&quot;&quot;&quot;

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.retry_config = config.get('retry_config', {})
        self.fallback_config = config.get('fallback_config', {})
        self.logger = logging.getLogger(__name__)

    async def handle_error(self, error: Exception, context: Dict[str, Any]) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;ç»Ÿä¸€é”™è¯¯å¤„ç†å…¥å£&quot;&quot;&quot;
        error_type = self._classify_error(error)

        self.logger.error(f&quot;Error occurred: {error_type} - {str(error)}&quot;)

        # æ ¹æ®é”™è¯¯ç±»å‹é€‰æ‹©å¤„ç†ç­–ç•¥
        if error_type == ErrorType.API_LIMIT_ERROR:
            return await self._handle_api_limit_error(error, context)
        elif error_type == ErrorType.NETWORK_ERROR:
            return await self._handle_network_error(error, context)
        elif error_type == ErrorType.TIMEOUT_ERROR:
            return await self._handle_timeout_error(error, context)
        elif error_type == ErrorType.DATA_NOT_FOUND:
            return await self._handle_data_not_found_error(error, context)
        else:
            return await self._handle_generic_error(error, context)

    def _classify_error(self, error: Exception) -&gt; ErrorType:
        &quot;&quot;&quot;é”™è¯¯åˆ†ç±»&quot;&quot;&quot;
        error_msg = str(error).lower()

        if 'rate limit' in error_msg or 'quota exceeded' in error_msg:
            return ErrorType.API_LIMIT_ERROR
        elif 'network' in error_msg or 'connection' in error_msg:
            return ErrorType.NETWORK_ERROR
        elif 'timeout' in error_msg:
            return ErrorType.TIMEOUT_ERROR
        elif 'not found' in error_msg or 'no data' in error_msg:
            return ErrorType.DATA_NOT_FOUND
        elif 'authentication' in error_msg or 'unauthorized' in error_msg:
            return ErrorType.AUTHENTICATION_ERROR
        elif 'server error' in error_msg or '500' in error_msg:
            return ErrorType.SERVER_ERROR
        else:
            return ErrorType.DATA_FORMAT_ERROR

    async def _handle_api_limit_error(self, error: Exception, context: Dict[str, Any]) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;å¤„ç†APIé™æµé”™è¯¯&quot;&quot;&quot;
        # 1. åˆ‡æ¢åˆ°å¤‡ç”¨æ•°æ®æº
        self.logger.warning(&quot;API limit reached, switching to fallback data source&quot;)

        # 2. å°è¯•ä»ç¼“å­˜è·å–æ•°æ®
        cache_manager = context.get('cache_manager')
        if cache_manager:
            stale_data = await cache_manager.get_stale(
                context.get('data_type'), 
                context.get('params')
            )
            if stale_data:
                return stale_data

        # 3. ä½¿ç”¨å¤‡ç”¨æ•°æ®æº
        fallback_fetcher = context.get('fallback_fetcher')
        if fallback_fetcher:
            return await fallback_fetcher.fetch_data(
                context.get('data_type'),
                context.get('params')
            )

        raise error

    async def _handle_network_error(self, error: Exception, context: Dict[str, Any]) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;å¤„ç†ç½‘ç»œé”™è¯¯&quot;&quot;&quot;
        # é‡è¯•æœºåˆ¶
        retry_count = context.get('retry_count', 0)
        max_retries = self.retry_config.get('max_retries', 3)

        if retry_count &lt; max_retries:
            self.logger.info(f&quot;Network error, retrying ({retry_count + 1}/{max_retries})&quot;)

            # æŒ‡æ•°é€€é¿
            wait_time = 2 ** retry_count
            await asyncio.sleep(wait_time)

            # æ›´æ–°é‡è¯•æ¬¡æ•°
            context['retry_count'] = retry_count + 1

            # é‡æ–°å°è¯•
            fetcher = context.get('fetcher')
            if fetcher:
                return await fetcher.fetch_data(
                    context.get('data_type'),
                    context.get('params')
                )

        # é‡è¯•å¤±è´¥ï¼Œä½¿ç”¨é™çº§ç­–ç•¥
        return await self._apply_fallback_strategy(error, context)

    async def _apply_fallback_strategy(self, error: Exception, context: Dict[str, Any]) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;åº”ç”¨é™çº§ç­–ç•¥&quot;&quot;&quot;
        # 1. å°è¯•ä»ç¼“å­˜è·å–è¿‡æœŸæ•°æ®
        cache_manager = context.get('cache_manager')
        if cache_manager:
            stale_data = await cache_manager.get_stale(
                context.get('data_type'),
                context.get('params')
            )
            if stale_data:
                self.logger.warning(&quot;Using stale cached data as fallback&quot;)
                return stale_data

        # 2. ä½¿ç”¨å¤‡ç”¨æ•°æ®æº
        fallback_fetcher = context.get('fallback_fetcher')
        if fallback_fetcher:
            try:
                self.logger.warning(&quot;Using fallback data source&quot;)
                return await fallback_fetcher.fetch_data(
                    context.get('data_type'),
                    context.get('params')
                )
            except Exception as fallback_error:
                self.logger.error(f&quot;Fallback data source also failed: {str(fallback_error)}&quot;)

        # 3. è¿”å›é»˜è®¤å€¼æˆ–æŠ›å‡ºå¼‚å¸¸
        default_data = self.fallback_config.get('default_data', {})
        if default_data:
            self.logger.warning(&quot;Using default fallback data&quot;)
            return default_data

        # æ‰€æœ‰é™çº§ç­–ç•¥éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºåŸå§‹å¼‚å¸¸
        raise error
</code></pre>
<h3 id="52">5.2 è‡ªåŠ¨é™çº§å’Œæ¢å¤æœºåˆ¶</h3>
<pre><code class="language-python">import asyncio
from datetime import datetime, timedelta
from typing import Dict, List

class AutoDegradationManager:
    &quot;&quot;&quot;è‡ªåŠ¨é™çº§ç®¡ç†å™¨&quot;&quot;&quot;

    def __init__(self, data_source_manager, config: Dict[str, Any]):
        self.data_source_manager = data_source_manager
        self.config = config
        self.degradation_rules = config.get('degradation_rules', {})
        self.recovery_rules = config.get('recovery_rules', {})
        self.current_degradations = {}
        self.logger = logging.getLogger(__name__)

    async def evaluate_degradation(self, source: DataSourceType, error_history: List[Dict]):
        &quot;&quot;&quot;è¯„ä¼°æ˜¯å¦éœ€è¦é™çº§&quot;&quot;&quot;
        # åˆ†æé”™è¯¯å†å²
        recent_errors = [e for e in error_history 
                        if datetime.now() - e['timestamp'] &lt; timedelta(minutes=5)]

        error_rate = len(recent_errors) / max(1, len(error_history))

        # æ£€æŸ¥é™çº§æ¡ä»¶
        if error_rate &gt; self.degradation_rules.get('error_rate_threshold', 0.5):
            await self._trigger_degradation(source, 'high_error_rate')

        # æ£€æŸ¥å“åº”æ—¶é—´
        avg_response_time = sum(e.get('response_time', 0) for e in recent_errors) / max(1, len(recent_errors))
        if avg_response_time &gt; self.degradation_rules.get('response_time_threshold', 10.0):
            await self._trigger_degradation(source, 'slow_response')

    async def _trigger_degradation(self, source: DataSourceType, reason: str):
        &quot;&quot;&quot;è§¦å‘é™çº§&quot;&quot;&quot;
        if source not in self.current_degradations:
            self.current_degradations[source] = {
                'reason': reason,
                'start_time': datetime.now(),
                'attempts': 0
            }

            self.logger.warning(f&quot;Triggering degradation for {source}: {reason}&quot;)

            # é€šçŸ¥æ•°æ®æºç®¡ç†å™¨
            await self.data_source_manager.set_source_status(source, DataSourceStatus.DEGRADED)

    async def evaluate_recovery(self):
        &quot;&quot;&quot;è¯„ä¼°æ¢å¤æ¡ä»¶&quot;&quot;&quot;
        for source, degradation_info in list(self.current_degradations.items()):
            # æ£€æŸ¥é™çº§æ—¶é—´
            degradation_duration = datetime.now() - degradation_info['start_time']
            min_degradation_time = timedelta(minutes=self.recovery_rules.get('min_degradation_minutes', 5))

            if degradation_duration &gt; min_degradation_time:
                # å°è¯•æ¢å¤æ£€æŸ¥
                if await self._test_recovery(source):
                    await self._trigger_recovery(source)

    async def _test_recovery(self, source: DataSourceType) -&gt; bool:
        &quot;&quot;&quot;æµ‹è¯•æ•°æ®æºæ˜¯å¦å¯ä»¥æ¢å¤&quot;&quot;&quot;
        try:
            # æ‰§è¡Œå¥åº·æ£€æŸ¥
            health_checker = self.data_source_manager.health_checker
            status = await health_checker.check_health(source)

            return status == DataSourceStatus.HEALTHY

        except Exception as e:
            self.logger.debug(f&quot;Recovery test failed for {source}: {str(e)}&quot;)
            return False

    async def _trigger_recovery(self, source: DataSourceType):
        &quot;&quot;&quot;è§¦å‘æ¢å¤&quot;&quot;&quot;
        if source in self.current_degradations:
            degradation_info = self.current_degradations[source]
            duration = datetime.now() - degradation_info['start_time']

            self.logger.info(f&quot;Recovering {source} after {duration}&quot;)

            # ç§»é™¤é™çº§çŠ¶æ€
            del self.current_degradations[source]

            # é€šçŸ¥æ•°æ®æºç®¡ç†å™¨
            await self.data_source_manager.set_source_status(source, DataSourceStatus.HEALTHY)

    async def start_monitoring(self):
        &quot;&quot;&quot;å¯åŠ¨è‡ªåŠ¨é™çº§ç›‘æ§&quot;&quot;&quot;
        while True:
            try:
                await self.evaluate_recovery()
                await asyncio.sleep(30)  # 30ç§’æ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                self.logger.error(f&quot;Auto degradation monitoring error: {str(e)}&quot;)
                await asyncio.sleep(60)
</code></pre>
<h2 id="6">6. ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ</h2>
<h3 id="61">6.1 ç›‘æ§æŒ‡æ ‡å®šä¹‰</h3>
<pre><code class="language-python">from dataclasses import dataclass
from typing import Dict, List, Optional
from datetime import datetime
import time

@dataclass
class MetricPoint:
    &quot;&quot;&quot;ç›‘æ§æŒ‡æ ‡æ•°æ®ç‚¹&quot;&quot;&quot;
    name: str
    value: float
    timestamp: datetime
    tags: Dict[str, str]
    unit: str = &quot;&quot;

class MetricsCollector:
    &quot;&quot;&quot;æŒ‡æ ‡æ”¶é›†å™¨&quot;&quot;&quot;

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.metrics_buffer = []
        self.counters = {}
        self.gauges = {}
        self.histograms = {}
        self.logger = logging.getLogger(__name__)

    def increment_counter(self, name: str, value: float = 1.0, tags: Dict[str, str] = None):
        &quot;&quot;&quot;é€’å¢è®¡æ•°å™¨&quot;&quot;&quot;
        key = self._make_key(name, tags or {})
        self.counters[key] = self.counters.get(key, 0) + value

        self._add_metric_point(MetricPoint(
            name=name,
            value=self.counters[key],
            timestamp=datetime.now(),
            tags=tags or {},
            unit=&quot;count&quot;
        ))

    def set_gauge(self, name: str, value: float, tags: Dict[str, str] = None):
        &quot;&quot;&quot;è®¾ç½®ä»ªè¡¨å€¼&quot;&quot;&quot;
        key = self._make_key(name, tags or {})
        self.gauges[key] = value

        self._add_metric_point(MetricPoint(
            name=name,
            value=value,
            timestamp=datetime.now(),
            tags=tags or {},
            unit=&quot;gauge&quot;
        ))

    def record_histogram(self, name: str, value: float, tags: Dict[str, str] = None):
        &quot;&quot;&quot;è®°å½•ç›´æ–¹å›¾å€¼&quot;&quot;&quot;
        key = self._make_key(name, tags or {})
        if key not in self.histograms:
            self.histograms[key] = []

        self.histograms[key].append(value)

        # ä¿æŒæœ€è¿‘1000ä¸ªå€¼
        if len(self.histograms[key]) &gt; 1000:
            self.histograms[key] = self.histograms[key][-1000:]

        self._add_metric_point(MetricPoint(
            name=name,
            value=value,
            timestamp=datetime.now(),
            tags=tags or {},
            unit=&quot;histogram&quot;
        ))

    def _make_key(self, name: str, tags: Dict[str, str]) -&gt; str:
        &quot;&quot;&quot;ç”ŸæˆæŒ‡æ ‡é”®&quot;&quot;&quot;
        tag_str = &quot;,&quot;.join(f&quot;{k}={v}&quot; for k, v in sorted(tags.items()))
        return f&quot;{name}[{tag_str}]&quot;

    def _add_metric_point(self, metric: MetricPoint):
        &quot;&quot;&quot;æ·»åŠ æŒ‡æ ‡ç‚¹åˆ°ç¼“å†²åŒº&quot;&quot;&quot;
        self.metrics_buffer.append(metric)

        # ç¼“å†²åŒºæ»¡æ—¶å‘é€
        if len(self.metrics_buffer) &gt;= 100:
            asyncio.create_task(self._flush_metrics())

    async def _flush_metrics(self):
        &quot;&quot;&quot;åˆ·æ–°æŒ‡æ ‡åˆ°ç›‘æ§ç³»ç»Ÿ&quot;&quot;&quot;
        if not self.metrics_buffer:
            return

        try:
            # å‘é€åˆ°Prometheusæˆ–å…¶ä»–ç›‘æ§ç³»ç»Ÿ
            await self._send_to_monitoring_system(self.metrics_buffer)
            self.metrics_buffer.clear()

        except Exception as e:
            self.logger.error(f&quot;Failed to flush metrics: {str(e)}&quot;)

    async def _send_to_monitoring_system(self, metrics: List[MetricPoint]):
        &quot;&quot;&quot;å‘é€æŒ‡æ ‡åˆ°ç›‘æ§ç³»ç»Ÿ&quot;&quot;&quot;
        # è¿™é‡Œå¯ä»¥é›†æˆPrometheusã€InfluxDBç­‰ç›‘æ§ç³»ç»Ÿ
        for metric in metrics:
            self.logger.debug(f&quot;Metric: {metric.name}={metric.value} {metric.tags}&quot;)

# æ ¸å¿ƒç›‘æ§æŒ‡æ ‡å®šä¹‰
CORE_METRICS = {
    # æ•°æ®æºæŒ‡æ ‡
    'data_source_requests_total': 'Counter - æ•°æ®æºè¯·æ±‚æ€»æ•°',
    'data_source_errors_total': 'Counter - æ•°æ®æºé”™è¯¯æ€»æ•°',
    'data_source_response_time': 'Histogram - æ•°æ®æºå“åº”æ—¶é—´',
    'data_source_availability': 'Gauge - æ•°æ®æºå¯ç”¨æ€§',

    # ç¼“å­˜æŒ‡æ ‡
    'cache_hits_total': 'Counter - ç¼“å­˜å‘½ä¸­æ€»æ•°',
    'cache_misses_total': 'Counter - ç¼“å­˜æœªå‘½ä¸­æ€»æ•°',
    'cache_hit_ratio': 'Gauge - ç¼“å­˜å‘½ä¸­ç‡',
    'cache_size_bytes': 'Gauge - ç¼“å­˜å¤§å°',

    # APIæŒ‡æ ‡
    'api_requests_total': 'Counter - APIè¯·æ±‚æ€»æ•°',
    'api_response_time': 'Histogram - APIå“åº”æ—¶é—´',
    'api_errors_total': 'Counter - APIé”™è¯¯æ€»æ•°',

    # ä¸šåŠ¡æŒ‡æ ‡
    'valuation_calculations_total': 'Counter - ä¼°å€¼è®¡ç®—æ€»æ•°',
    'valuation_calculation_time': 'Histogram - ä¼°å€¼è®¡ç®—æ—¶é—´',
    'active_users': 'Gauge - æ´»è·ƒç”¨æˆ·æ•°'
}
</code></pre>
<h3 id="62">6.2 å‘Šè­¦è§„åˆ™é…ç½®</h3>
<pre><code class="language-yaml"># å‘Šè­¦è§„åˆ™é…ç½®
alert_rules:
  # æ•°æ®æºå‘Šè­¦
  data_source_down:
    metric: data_source_availability
    condition: &quot;&lt; 0.5&quot;
    duration: &quot;2m&quot;
    severity: critical
    message: &quot;æ•°æ®æº {{$labels.source}} ä¸å¯ç”¨&quot;

  data_source_slow:
    metric: data_source_response_time
    condition: &quot;&gt; 10&quot;
    duration: &quot;5m&quot;
    severity: warning
    message: &quot;æ•°æ®æº {{$labels.source}} å“åº”ç¼“æ…¢&quot;

  high_error_rate:
    metric: rate(data_source_errors_total[5m])
    condition: &quot;&gt; 0.1&quot;
    duration: &quot;3m&quot;
    severity: warning
    message: &quot;æ•°æ®æº {{$labels.source}} é”™è¯¯ç‡è¿‡é«˜&quot;

  # ç¼“å­˜å‘Šè­¦
  low_cache_hit_ratio:
    metric: cache_hit_ratio
    condition: &quot;&lt; 0.7&quot;
    duration: &quot;10m&quot;
    severity: warning
    message: &quot;ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {{$value}}&quot;

  cache_size_high:
    metric: cache_size_bytes
    condition: &quot;&gt; 8GB&quot;
    duration: &quot;5m&quot;
    severity: warning
    message: &quot;ç¼“å­˜ä½¿ç”¨é‡è¿‡é«˜: {{$value}}&quot;

  # APIå‘Šè­¦
  api_response_slow:
    metric: api_response_time
    condition: &quot;&gt; 5&quot;
    duration: &quot;5m&quot;
    severity: warning
    message: &quot;APIå“åº”æ—¶é—´è¿‡é•¿: {{$value}}s&quot;

  api_error_rate_high:
    metric: rate(api_errors_total[5m])
    condition: &quot;&gt; 0.05&quot;
    duration: &quot;3m&quot;
    severity: critical
    message: &quot;APIé”™è¯¯ç‡è¿‡é«˜: {{$value}}&quot;

# å‘Šè­¦é€šçŸ¥é…ç½®
notification_channels:
  email:
    enabled: true
    smtp_server: &quot;smtp.example.com&quot;
    recipients: [&quot;admin@example.com&quot;]

  slack:
    enabled: true
    webhook_url: &quot;https://hooks.slack.com/services/...&quot;
    channel: &quot;#alerts&quot;

  webhook:
    enabled: false
    url: &quot;https://api.example.com/alerts&quot;
</code></pre>
<h3 id="63">6.3 ç›‘æ§ä»ªè¡¨æ¿</h3>
<pre><code class="language-python">class MonitoringDashboard:
    &quot;&quot;&quot;ç›‘æ§ä»ªè¡¨æ¿&quot;&quot;&quot;

    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics_collector = metrics_collector
        self.dashboard_config = self._load_dashboard_config()

    def _load_dashboard_config(self) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;åŠ è½½ä»ªè¡¨æ¿é…ç½®&quot;&quot;&quot;
        return {
            'panels': [
                {
                    'title': 'æ•°æ®æºçŠ¶æ€',
                    'type': 'stat',
                    'metrics': ['data_source_availability'],
                    'thresholds': [0.9, 0.95]
                },
                {
                    'title': 'å“åº”æ—¶é—´è¶‹åŠ¿',
                    'type': 'graph',
                    'metrics': ['data_source_response_time', 'api_response_time'],
                    'time_range': '1h'
                },
                {
                    'title': 'ç¼“å­˜æ€§èƒ½',
                    'type': 'graph',
                    'metrics': ['cache_hit_ratio', 'cache_hits_total', 'cache_misses_total'],
                    'time_range': '6h'
                },
                {
                    'title': 'é”™è¯¯ç‡ç»Ÿè®¡',
                    'type': 'graph',
                    'metrics': ['data_source_errors_total', 'api_errors_total'],
                    'time_range': '24h'
                },
                {
                    'title': 'ä¸šåŠ¡æŒ‡æ ‡',
                    'type': 'stat',
                    'metrics': ['valuation_calculations_total', 'active_users'],
                    'time_range': '1d'
                }
            ]
        }

    async def get_dashboard_data(self) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;è·å–ä»ªè¡¨æ¿æ•°æ®&quot;&quot;&quot;
        dashboard_data = {
            'timestamp': datetime.now().isoformat(),
            'panels': []
        }

        for panel_config in self.dashboard_config['panels']:
            panel_data = await self._get_panel_data(panel_config)
            dashboard_data['panels'].append(panel_data)

        return dashboard_data

    async def _get_panel_data(self, panel_config: Dict[str, Any]) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;è·å–é¢æ¿æ•°æ®&quot;&quot;&quot;
        panel_data = {
            'title': panel_config['title'],
            'type': panel_config['type'],
            'data': []
        }

        for metric_name in panel_config['metrics']:
            metric_data = await self._get_metric_data(
                metric_name, 
                panel_config.get('time_range', '1h')
            )
            panel_data['data'].append(metric_data)

        return panel_data

    async def _get_metric_data(self, metric_name: str, time_range: str) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;è·å–æŒ‡æ ‡æ•°æ®&quot;&quot;&quot;
        # è¿™é‡Œåº”è¯¥ä»æ—¶åºæ•°æ®åº“æŸ¥è¯¢æ•°æ®
        # ä¸ºäº†ç¤ºä¾‹ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        return {
            'metric': metric_name,
            'values': [],  # å®é™…çš„æ—¶åºæ•°æ®ç‚¹
            'current_value': 0.0,
            'trend': 'stable'  # up, down, stable
        }
</code></pre>
<h2 id="7">7. é…ç½®ç®¡ç†</h2>
<h3 id="71">7.1 ç¯å¢ƒé…ç½®æ–‡ä»¶</h3>
<pre><code class="language-bash"># .env é…ç½®æ–‡ä»¶

# ==================== æ•°æ®æºé…ç½® ====================
# ä¸»æ•°æ®æºé€‰æ‹©: tushare, postgresql
PRIMARY_DATA_SOURCE=tushare

# å¤‡ç”¨æ•°æ®æºé€‰æ‹©: postgresql, tushare
FALLBACK_DATA_SOURCE=postgresql

# å¼ºåˆ¶ä½¿ç”¨æŒ‡å®šæ•°æ®æº (å¯é€‰): tushare, postgresql
# FORCE_DATA_SOURCE=tushare

# ==================== Tushareé…ç½® ====================
TUSHARE_TOKEN=your_tushare_token_here
TUSHARE_API_URL=http://api.tushare.pro
TUSHARE_TIMEOUT=30
TUSHARE_MAX_RETRIES=3
TUSHARE_RETRY_DELAY=1

# APIé…é¢ç®¡ç†
TUSHARE_DAILY_LIMIT=10000
TUSHARE_MINUTE_LIMIT=500
TUSHARE_ENABLE_QUOTA_CHECK=true

# ==================== PostgreSQLé…ç½® ====================
POSTGRESQL_HOST=localhost
POSTGRESQL_PORT=5432
POSTGRESQL_DATABASE=stock_valuation
POSTGRESQL_USERNAME=postgres
POSTGRESQL_PASSWORD=your_password_here
POSTGRESQL_POOL_SIZE=10
POSTGRESQL_MAX_OVERFLOW=20
POSTGRESQL_POOL_TIMEOUT=30

# ==================== Redisç¼“å­˜é…ç½® ====================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_MAX_CONNECTIONS=10
REDIS_SOCKET_TIMEOUT=5

# ==================== ç¼“å­˜ç­–ç•¥é…ç½® ====================
# å¯ç”¨ç¼“å­˜å±‚çº§: memory, redis, file
ENABLE_MEMORY_CACHE=true
ENABLE_REDIS_CACHE=true
ENABLE_FILE_CACHE=true

# ç¼“å­˜ç›®å½•
FILE_CACHE_DIR=./cache

# ç¼“å­˜TTL (ç§’)
CACHE_TTL_STOCK_BASIC_MEMORY=3600
CACHE_TTL_STOCK_BASIC_REDIS=86400
CACHE_TTL_DAILY_BASIC_MEMORY=1800
CACHE_TTL_DAILY_BASIC_REDIS=3600
CACHE_TTL_FINANCIAL_DATA_MEMORY=7200
CACHE_TTL_FINANCIAL_DATA_REDIS=43200

# ==================== å¥åº·æ£€æŸ¥é…ç½® ====================
HEALTH_CHECK_INTERVAL=60
HEALTH_CHECK_TIMEOUT=10
HEALTH_CHECK_RETRY_COUNT=3

# å¥åº·çŠ¶æ€é˜ˆå€¼
HEALTH_RESPONSE_TIME_HEALTHY=2.0
HEALTH_RESPONSE_TIME_DEGRADED=5.0

# ==================== é™çº§ç­–ç•¥é…ç½® ====================
# å¯ç”¨è‡ªåŠ¨é™çº§
ENABLE_AUTO_DEGRADATION=true

# é™çº§è§¦å‘æ¡ä»¶
DEGRADATION_ERROR_RATE_THRESHOLD=0.5
DEGRADATION_RESPONSE_TIME_THRESHOLD=10.0
DEGRADATION_MIN_DURATION_MINUTES=5

# æ¢å¤æ¡ä»¶
RECOVERY_SUCCESS_RATE_THRESHOLD=0.9
RECOVERY_TEST_INTERVAL=30

# ==================== ç›‘æ§å‘Šè­¦é…ç½® ====================
# å¯ç”¨ç›‘æ§
ENABLE_MONITORING=true
MONITORING_INTERVAL=30

# Prometheusé…ç½®
PROMETHEUS_ENABLED=false
PROMETHEUS_HOST=localhost
PROMETHEUS_PORT=9090

# å‘Šè­¦é…ç½®
ALERT_EMAIL_ENABLED=true
ALERT_EMAIL_SMTP_SERVER=smtp.example.com
ALERT_EMAIL_RECIPIENTS=admin@example.com

ALERT_SLACK_ENABLED=false
ALERT_SLACK_WEBHOOK_URL=

# ==================== æ—¥å¿—é…ç½® ====================
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FILE_PATH=./logs/stock_valuation.log
LOG_MAX_SIZE=100MB
LOG_BACKUP_COUNT=5

# ==================== æ€§èƒ½é…ç½® ====================
# è¿æ¥æ± é…ç½®
CONNECTION_POOL_SIZE=10
CONNECTION_POOL_MAX_OVERFLOW=20
CONNECTION_POOL_TIMEOUT=30

# å¼‚æ­¥é…ç½®
ASYNC_WORKER_COUNT=4
ASYNC_QUEUE_SIZE=1000

# é™æµé…ç½®
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS_PER_MINUTE=1000
RATE_LIMIT_BURST_SIZE=100
</code></pre>
<h3 id="72">7.2 é…ç½®åŠ è½½å™¨</h3>
<pre><code class="language-python">import os
from typing import Dict, Any, Optional
from dataclasses import dataclass
from pathlib import Path

@dataclass
class DataSourceConfig:
    &quot;&quot;&quot;æ•°æ®æºé…ç½®&quot;&quot;&quot;
    primary_source: str
    fallback_source: str
    force_source: Optional[str] = None

@dataclass
class TushareConfig:
    &quot;&quot;&quot;Tushareé…ç½®&quot;&quot;&quot;
    token: str
    api_url: str = &quot;http://api.tushare.pro&quot;
    timeout: int = 30
    max_retries: int = 3
    retry_delay: int = 1
    daily_limit: int = 10000
    minute_limit: int = 500
    enable_quota_check: bool = True

@dataclass
class PostgreSQLConfig:
    &quot;&quot;&quot;PostgreSQLé…ç½®&quot;&quot;&quot;
    host: str = &quot;localhost&quot;
    port: int = 5432
    database: str = &quot;stock_valuation&quot;
    username: str = &quot;postgres&quot;
    password: str = &quot;&quot;
    pool_size: int = 10
    max_overflow: int = 20
    pool_timeout: int = 30

@dataclass
class CacheConfig:
    &quot;&quot;&quot;ç¼“å­˜é…ç½®&quot;&quot;&quot;
    enable_memory: bool = True
    enable_redis: bool = True
    enable_file: bool = True
    file_cache_dir: str = &quot;./cache&quot;
    redis_host: str = &quot;localhost&quot;
    redis_port: int = 6379
    redis_db: int = 0
    redis_password: str = &quot;&quot;

class ConfigLoader:
    &quot;&quot;&quot;é…ç½®åŠ è½½å™¨&quot;&quot;&quot;

    def __init__(self, env_file: str = &quot;.env&quot;):
        self.env_file = env_file
        self._load_env_file()

    def _load_env_file(self):
        &quot;&quot;&quot;åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶&quot;&quot;&quot;
        if Path(self.env_file).exists():
            with open(self.env_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip()

    def get_data_source_config(self) -&gt; DataSourceConfig:
        &quot;&quot;&quot;è·å–æ•°æ®æºé…ç½®&quot;&quot;&quot;
        return DataSourceConfig(
            primary_source=os.getenv('PRIMARY_DATA_SOURCE', 'tushare'),
            fallback_source=os.getenv('FALLBACK_DATA_SOURCE', 'postgresql'),
            force_source=os.getenv('FORCE_DATA_SOURCE')
        )

    def get_tushare_config(self) -&gt; TushareConfig:
        &quot;&quot;&quot;è·å–Tushareé…ç½®&quot;&quot;&quot;
        token = os.getenv('TUSHARE_TOKEN')
        if not token:
            raise ValueError(&quot;TUSHARE_TOKEN is required&quot;)

        return TushareConfig(
            token=token,
            api_url=os.getenv('TUSHARE_API_URL', 'http://api.tushare.pro'),
            timeout=int(os.getenv('TUSHARE_TIMEOUT', '30')),
            max_retries=int(os.getenv('TUSHARE_MAX_RETRIES', '3')),
            retry_delay=int(os.getenv('TUSHARE_RETRY_DELAY', '1')),
            daily_limit=int(os.getenv('TUSHARE_DAILY_LIMIT', '10000')),
            minute_limit=int(os.getenv('TUSHARE_MINUTE_LIMIT', '500')),
            enable_quota_check=os.getenv('TUSHARE_ENABLE_QUOTA_CHECK', 'true').lower() == 'true'
        )

    def get_postgresql_config(self) -&gt; PostgreSQLConfig:
        &quot;&quot;&quot;è·å–PostgreSQLé…ç½®&quot;&quot;&quot;
        return PostgreSQLConfig(
            host=os.getenv('POSTGRESQL_HOST', 'localhost'),
            port=int(os.getenv('POSTGRESQL_PORT', '5432')),
            database=os.getenv('POSTGRESQL_DATABASE', 'stock_valuation'),
            username=os.getenv('POSTGRESQL_USERNAME', 'postgres'),
            password=os.getenv('POSTGRESQL_PASSWORD', ''),
            pool_size=int(os.getenv('POSTGRESQL_POOL_SIZE', '10')),
            max_overflow=int(os.getenv('POSTGRESQL_MAX_OVERFLOW', '20')),
            pool_timeout=int(os.getenv('POSTGRESQL_POOL_TIMEOUT', '30'))
        )

    def get_cache_config(self) -&gt; CacheConfig:
        &quot;&quot;&quot;è·å–ç¼“å­˜é…ç½®&quot;&quot;&quot;
        return CacheConfig(
            enable_memory=os.getenv('ENABLE_MEMORY_CACHE', 'true').lower() == 'true',
            enable_redis=os.getenv('ENABLE_REDIS_CACHE', 'true').lower() == 'true',
            enable_file=os.getenv('ENABLE_FILE_CACHE', 'true').lower() == 'true',
            file_cache_dir=os.getenv('FILE_CACHE_DIR', './cache'),
            redis_host=os.getenv('REDIS_HOST', 'localhost'),
            redis_port=int(os.getenv('REDIS_PORT', '6379')),
            redis_db=int(os.getenv('REDIS_DB', '0')),
            redis_password=os.getenv('REDIS_PASSWORD', '')
        )

    def get_full_config(self) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;è·å–å®Œæ•´é…ç½®&quot;&quot;&quot;
        return {
            'data_source': self.get_data_source_config(),
            'tushare': self.get_tushare_config(),
            'postgresql': self.get_postgresql_config(),
            'cache': self.get_cache_config(),
            'monitoring': {
                'enabled': os.getenv('ENABLE_MONITORING', 'true').lower() == 'true',
                'interval': int(os.getenv('MONITORING_INTERVAL', '30'))
            },
            'logging': {
                'level': os.getenv('LOG_LEVEL', 'INFO'),
                'format': os.getenv('LOG_FORMAT', '%(asctime)s - %(name)s - %(levelname)s - %(message)s'),
                'file_path': os.getenv('LOG_FILE_PATH', './logs/stock_valuation.log')
            }
        }
</code></pre>
<h2 id="8">8. éƒ¨ç½²æ–¹æ¡ˆ</h2>
<h3 id="81-docker">8.1 Dockerå®¹å™¨åŒ–éƒ¨ç½²</h3>
<pre><code class="language-dockerfile"># Dockerfile
FROM python:3.9-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update &amp;&amp; apt-get install -y \
    gcc \
    g++ \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºç¼“å­˜ç›®å½•
RUN mkdir -p /app/cache /app/logs

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD [&quot;python&quot;, &quot;-m&quot;, &quot;uvicorn&quot;, &quot;main:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]
</code></pre>
<pre><code class="language-yaml"># docker-compose.yml
version: '3.8'

services:
  stock-valuation:
    build: .
    ports:
      - &quot;8000:8000&quot;
    environment:
      - PRIMARY_DATA_SOURCE=tushare
      - FALLBACK_DATA_SOURCE=postgresql
      - TUSHARE_TOKEN=${TUSHARE_TOKEN}
      - POSTGRESQL_HOST=postgres
      - REDIS_HOST=redis
    depends_on:
      - postgres
      - redis
    volumes:
      - ./cache:/app/cache
      - ./logs:/app/logs
    restart: unless-stopped
    networks:
      - stock-network

  postgres:
    image: postgres:13
    environment:
      - POSTGRES_DB=stock_valuation
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - &quot;5432:5432&quot;
    restart: unless-stopped
    networks:
      - stock-network

  redis:
    image: redis:6-alpine
    ports:
      - &quot;6379:6379&quot;
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - stock-network

  prometheus:
    image: prom/prometheus:latest
    ports:
      - &quot;9090:9090&quot;
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    restart: unless-stopped
    networks:
      - stock-network

  grafana:
    image: grafana/grafana:latest
    ports:
      - &quot;3000:3000&quot;
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    restart: unless-stopped
    networks:
      - stock-network

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  stock-network:
    driver: bridge
</code></pre>
<h3 id="82-kubernetes">8.2 Kuberneteséƒ¨ç½²</h3>
<pre><code class="language-yaml"># k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: stock-valuation
  labels:
    app: stock-valuation
spec:
  replicas: 3
  selector:
    matchLabels:
      app: stock-valuation
  template:
    metadata:
      labels:
        app: stock-valuation
    spec:
      containers:
      - name: stock-valuation
        image: stock-valuation:latest
        ports:
        - containerPort: 8000
        env:
        - name: PRIMARY_DATA_SOURCE
          value: &quot;tushare&quot;
        - name: FALLBACK_DATA_SOURCE
          value: &quot;postgresql&quot;
        - name: TUSHARE_TOKEN
          valueFrom:
            secretKeyRef:
              name: tushare-secret
              key: token
        - name: POSTGRESQL_HOST
          value: &quot;postgres-service&quot;
        - name: REDIS_HOST
          value: &quot;redis-service&quot;
        resources:
          requests:
            memory: &quot;512Mi&quot;
            cpu: &quot;250m&quot;
          limits:
            memory: &quot;1Gi&quot;
            cpu: &quot;500m&quot;
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: cache-volume
          mountPath: /app/cache
        - name: logs-volume
          mountPath: /app/logs
      volumes:
      - name: cache-volume
        emptyDir: {}
      - name: logs-volume
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: stock-valuation-service
spec:
  selector:
    app: stock-valuation
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
</code></pre>
<h2 id="9">9. å®æ–½è®¡åˆ’</h2>
<h3 id="91">9.1 å®æ–½é˜¶æ®µåˆ’åˆ†</h3>
<h4 id="1-2">ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ¶æ„æ­å»º (1-2å‘¨)</h4>
<p><strong>ç›®æ ‡</strong>: å»ºç«‹æ··åˆæ•°æ®æºçš„åŸºç¡€æ¡†æ¶</p>
<p><strong>ä»»åŠ¡æ¸…å•</strong>:
- [ ] åˆ›å»ºDataSourceManageræ ¸å¿ƒç±»
- [ ] å®ç°TushareDataFetcher
- [ ] å®ç°PostgreSQLDataFetcher
- [ ] å»ºç«‹åŸºç¡€çš„é…ç½®ç®¡ç†ç³»ç»Ÿ
- [ ] å®ç°ç®€å•çš„æ•°æ®æºåˆ‡æ¢é€»è¾‘</p>
<p><strong>éªŒæ”¶æ ‡å‡†</strong>:
- èƒ½å¤Ÿé€šè¿‡é…ç½®åˆ‡æ¢æ•°æ®æº
- åŸºæœ¬çš„æ•°æ®è·å–åŠŸèƒ½æ­£å¸¸
- å•å…ƒæµ‹è¯•è¦†ç›–ç‡è¾¾åˆ°80%</p>
<h4 id="1-2_1">ç¬¬äºŒé˜¶æ®µï¼šç¼“å­˜ç³»ç»Ÿå®ç° (1-2å‘¨)</h4>
<p><strong>ç›®æ ‡</strong>: å®ç°å¤šå±‚çº§ç¼“å­˜æœºåˆ¶</p>
<p><strong>ä»»åŠ¡æ¸…å•</strong>:
- [ ] å®ç°CacheManagerç±»
- [ ] é›†æˆRedisç¼“å­˜
- [ ] å®ç°æœ¬åœ°æ–‡ä»¶ç¼“å­˜
- [ ] å»ºç«‹ç¼“å­˜å¤±æ•ˆç­–ç•¥
- [ ] ä¼˜åŒ–ç¼“å­˜é”®ç”Ÿæˆç®—æ³•</p>
<p><strong>éªŒæ”¶æ ‡å‡†</strong>:
- ç¼“å­˜å‘½ä¸­ç‡è¾¾åˆ°70%ä»¥ä¸Š
- ç¼“å­˜æ•°æ®ä¸€è‡´æ€§ä¿è¯
- ç¼“å­˜æ€§èƒ½æµ‹è¯•é€šè¿‡</p>
<h4 id="1_1">ç¬¬ä¸‰é˜¶æ®µï¼šå¥åº·æ£€æŸ¥å’Œé™çº§ (1å‘¨)</h4>
<p><strong>ç›®æ ‡</strong>: å®ç°è‡ªåŠ¨å¥åº·æ£€æŸ¥å’Œé™çº§æœºåˆ¶</p>
<p><strong>ä»»åŠ¡æ¸…å•</strong>:
- [ ] å®ç°HealthCheckerç±»
- [ ] å»ºç«‹æ•°æ®æºçŠ¶æ€ç›‘æ§
- [ ] å®ç°è‡ªåŠ¨é™çº§é€»è¾‘
- [ ] å»ºç«‹æ¢å¤æœºåˆ¶
- [ ] å®ç°é”™è¯¯å¤„ç†ç­–ç•¥</p>
<p><strong>éªŒæ”¶æ ‡å‡†</strong>:
- æ•°æ®æºæ•…éšœè‡ªåŠ¨æ£€æµ‹
- é™çº§åˆ‡æ¢æ—¶é—´&lt;5ç§’
- æ¢å¤æœºåˆ¶æ­£å¸¸å·¥ä½œ</p>
<h4 id="1_2">ç¬¬å››é˜¶æ®µï¼šç›‘æ§å‘Šè­¦ç³»ç»Ÿ (1å‘¨)</h4>
<p><strong>ç›®æ ‡</strong>: å»ºç«‹å®Œæ•´çš„ç›‘æ§å‘Šè­¦ä½“ç³»</p>
<p><strong>ä»»åŠ¡æ¸…å•</strong>:
- [ ] å®ç°MetricsCollector
- [ ] é›†æˆPrometheusç›‘æ§
- [ ] å»ºç«‹å‘Šè­¦è§„åˆ™
- [ ] åˆ›å»ºç›‘æ§ä»ªè¡¨æ¿
- [ ] å®ç°å‘Šè­¦é€šçŸ¥</p>
<p><strong>éªŒæ”¶æ ‡å‡†</strong>:
- å…³é”®æŒ‡æ ‡ç›‘æ§è¦†ç›–
- å‘Šè­¦åŠæ—¶å‡†ç¡®
- ä»ªè¡¨æ¿æ•°æ®å®Œæ•´</p>
<h4 id="1-2_2">ç¬¬äº”é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ–å’Œæµ‹è¯• (1-2å‘¨)</h4>
<p><strong>ç›®æ ‡</strong>: ç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–å’Œå…¨é¢æµ‹è¯•</p>
<p><strong>ä»»åŠ¡æ¸…å•</strong>:
- [ ] æ€§èƒ½å‹åŠ›æµ‹è¯•
- [ ] å¹¶å‘å®‰å…¨æµ‹è¯•
- [ ] æ•…éšœæ¢å¤æµ‹è¯•
- [ ] æ•°æ®ä¸€è‡´æ€§æµ‹è¯•
- [ ] ç”¨æˆ·éªŒæ”¶æµ‹è¯•</p>
<p><strong>éªŒæ”¶æ ‡å‡†</strong>:
- ç³»ç»Ÿå“åº”æ—¶é—´&lt;2ç§’
- å¹¶å‘ç”¨æˆ·æ•°&gt;100
- æ•°æ®å‡†ç¡®æ€§99.9%
- ç³»ç»Ÿå¯ç”¨æ€§99.5%</p>
<h3 id="92">9.2 é£é™©æ§åˆ¶æªæ–½</h3>
<h4 id="_6">æŠ€æœ¯é£é™©</h4>
<table>
<thead>
<tr>
<th>é£é™©é¡¹</th>
<th>é£é™©ç­‰çº§</th>
<th>å½±å“</th>
<th>åº”å¯¹æªæ–½</th>
</tr>
</thead>
<tbody>
<tr>
<td>Tushare APIå˜æ›´</td>
<td>ä¸­</td>
<td>æ•°æ®è·å–å¤±è´¥</td>
<td>ç‰ˆæœ¬é”å®šã€é€‚é…å±‚è®¾è®¡</td>
</tr>
<tr>
<td>æ•°æ®æºåŒæ­¥å»¶è¿Ÿ</td>
<td>ä¸­</td>
<td>æ•°æ®ä¸ä¸€è‡´</td>
<td>æ—¶é—´æˆ³æ ¡éªŒã€å¢é‡åŒæ­¥</td>
</tr>
<tr>
<td>ç¼“å­˜æ•°æ®è¿‡æœŸ</td>
<td>ä½</td>
<td>æ€§èƒ½ä¸‹é™</td>
<td>æ™ºèƒ½é¢„åŠ è½½ã€è¿‡æœŸç­–ç•¥</td>
</tr>
<tr>
<td>å¹¶å‘è®¿é—®å†²çª</td>
<td>ä¸­</td>
<td>æ•°æ®é”™è¯¯</td>
<td>é”æœºåˆ¶ã€é˜Ÿåˆ—ç®¡ç†</td>
</tr>
</tbody>
</table>
<h4 id="_7">ä¸šåŠ¡é£é™©</h4>
<table>
<thead>
<tr>
<th>é£é™©é¡¹</th>
<th>é£é™©ç­‰çº§</th>
<th>å½±å“</th>
<th>åº”å¯¹æªæ–½</th>
</tr>
</thead>
<tbody>
<tr>
<td>æ•°æ®æºæˆæœ¬ä¸Šå‡</td>
<td>ä¸­</td>
<td>è¿è¥æˆæœ¬å¢åŠ </td>
<td>æˆæœ¬ç›‘æ§ã€ç”¨é‡ä¼˜åŒ–</td>
</tr>
<tr>
<td>æœåŠ¡ä¸­æ–­</td>
<td>é«˜</td>
<td>ä¸šåŠ¡åœæ­¢</td>
<td>å¤šé‡å¤‡ä»½ã€å¿«é€Ÿæ¢å¤</td>
</tr>
<tr>
<td>æ•°æ®è´¨é‡é—®é¢˜</td>
<td>ä¸­</td>
<td>è®¡ç®—é”™è¯¯</td>
<td>æ•°æ®æ ¡éªŒã€è´¨é‡ç›‘æ§</td>
</tr>
</tbody>
</table>
<h3 id="93">9.3 æˆåŠŸæŒ‡æ ‡</h3>
<h4 id="_8">æŠ€æœ¯æŒ‡æ ‡</h4>
<ul>
<li><strong>ç³»ç»Ÿå¯ç”¨æ€§</strong>: â‰¥99.5%</li>
<li><strong>å“åº”æ—¶é—´</strong>: â‰¤2ç§’ (95%è¯·æ±‚)</li>
<li><strong>ç¼“å­˜å‘½ä¸­ç‡</strong>: â‰¥70%</li>
<li><strong>é”™è¯¯ç‡</strong>: â‰¤0.1%</li>
<li><strong>æ•°æ®å‡†ç¡®æ€§</strong>: â‰¥99.9%</li>
</ul>
<h4 id="_9">ä¸šåŠ¡æŒ‡æ ‡</h4>
<ul>
<li><strong>APIè°ƒç”¨æˆæœ¬</strong>: é™ä½60%</li>
<li><strong>æ•°æ®æ›´æ–°é¢‘ç‡</strong>: æå‡50%</li>
<li><strong>ç”¨æˆ·æ»¡æ„åº¦</strong>: â‰¥90%</li>
<li><strong>ç³»ç»Ÿç»´æŠ¤æˆæœ¬</strong>: é™ä½40%</li>
</ul>
<h2 id="10">10. æ€»ç»“</h2>
<h3 id="101">10.1 æ¶æ„ä¼˜åŠ¿æ€»ç»“</h3>
<ol>
<li><strong>é«˜å¯é æ€§</strong>: åŒæ•°æ®æºä¿éšœï¼Œå•ç‚¹æ•…éšœé£é™©é™ä½90%</li>
<li><strong>é«˜æ€§èƒ½</strong>: å¤šå±‚ç¼“å­˜æœºåˆ¶ï¼Œæ•°æ®è®¿é—®é€Ÿåº¦æå‡70%</li>
<li><strong>æˆæœ¬ä¼˜åŒ–</strong>: æ™ºèƒ½APIè°ƒç”¨ç®¡ç†ï¼Œæˆæœ¬é™ä½60%</li>
<li><strong>æ˜“ç»´æŠ¤</strong>: æ¨¡å—åŒ–è®¾è®¡ï¼Œç»´æŠ¤æˆæœ¬é™ä½40%</li>
<li><strong>å¯æ‰©å±•</strong>: æ”¯æŒæ–°æ•°æ®æºæ¥å…¥ï¼Œæ‰©å±•æ€§å¼º</li>
</ol>
<h3 id="102">10.2 å…³é”®æŠ€æœ¯åˆ›æ–°</h3>
<ul>
<li><strong>æ™ºèƒ½æ•°æ®æºè·¯ç”±</strong>: åŸºäºå¥åº·çŠ¶æ€å’Œæ€§èƒ½çš„åŠ¨æ€é€‰æ‹©</li>
<li><strong>å¤šå±‚çº§ç¼“å­˜</strong>: å†…å­˜+Redis+æ–‡ä»¶çš„ä¸‰çº§ç¼“å­˜ä½“ç³»</li>
<li><strong>è‡ªåŠ¨é™çº§æ¢å¤</strong>: æ— äººå·¥å¹²é¢„çš„æ•…éšœå¤„ç†æœºåˆ¶</li>
<li><strong>å®æ—¶ç›‘æ§å‘Šè­¦</strong>: å…¨æ–¹ä½çš„ç³»ç»ŸçŠ¶æ€ç›‘æ§</li>
</ul>
<h3 id="103">10.3 åç»­å‘å±•æ–¹å‘</h3>
<ol>
<li><strong>AIé©±åŠ¨ä¼˜åŒ–</strong>: åŸºäºæœºå™¨å­¦ä¹ çš„ç¼“å­˜ç­–ç•¥ä¼˜åŒ–</li>
<li><strong>å¤šäº‘éƒ¨ç½²</strong>: æ”¯æŒå¤šäº‘ç¯å¢ƒçš„æ•°æ®æºåˆ†å¸ƒ</li>
<li><strong>å®æ—¶æµå¤„ç†</strong>: é›†æˆæµå¼æ•°æ®å¤„ç†èƒ½åŠ›</li>
<li><strong>è¾¹ç¼˜è®¡ç®—</strong>: æ”¯æŒè¾¹ç¼˜èŠ‚ç‚¹çš„æ•°æ®ç¼“å­˜</li>
</ol>
<hr />
<p><strong>æ–‡æ¡£ç‰ˆæœ¬</strong>: v1.0<br />
<strong>æœ€åæ›´æ–°</strong>: 2025å¹´1æœˆ<br />
<strong>ä¸‹æ¬¡å®¡æ ¸</strong>: 2025å¹´3æœˆ</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js"></script>
        <script src="../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
